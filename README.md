# ğŸ­ Real-Time Emotion Detection System

![Python](https://img.shields.io/badge/Python-3.10-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-red)
![Computer Vision](https://img.shields.io/badge/Computer%20Vision-OpenCV-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

---

## ğŸš€ Overview

This project implements a **real-time human emotion detection system** using deep learning and computer vision.  
It captures live video from a webcam, detects faces, and predicts **facial emotions in real time**.

The system is designed to be:
- **Efficient** (runs on Apple Silicon / CPU)
- **Modular** (clean project structure)
- **Reproducible** (training pipeline included)
- **Interview-ready** (professional ML practices)

---

## ğŸ¯ Emotions Detected

The model predicts the following **7 basic human emotions**:

- ğŸ˜  Angry  
- ğŸ¤¢ Disgust  
- ğŸ˜¨ Fear  
- ğŸ˜Š Happy  
- ğŸ˜¢ Sad  
- ğŸ˜² Surprise  
- ğŸ˜ Neutral  

---

## ğŸ§  Model Architecture

- **Model:** MobileNet-V2 (CNN)
- **Training strategy:** Transfer Learning
- **Pretrained on:** ImageNet
- **Classifier head:** Fully connected layer (7 classes)

### Why MobileNet-V2?
- Lightweight and fast
- Optimized for edge devices
- Ideal for real-time inference
- Performs well on limited hardware (MacBook Air M2)

---

## ğŸ“Š Dataset

- **Dataset:** FER-2013 (Facial Expression Recognition)
- **Source:** Kaggle
- **Image format:** Grayscale facial images
- **Original size:** 48Ã—48 pixels
- **Classes:** 7 emotions

### Preprocessing Steps
- CSV â†’ image folder conversion
- Resized to 224Ã—224
- Normalization (ImageNet mean & std)
- Data augmentation (horizontal flip)

---

## âš™ï¸ Training Details

- **Framework:** PyTorch
- **Loss function:** CrossEntropyLoss
- **Optimizer:** Adam
- **Learning rate:** 1e-4
- **Batch size:** 16
- **Epochs:** 10
- **Device:** Apple MPS (Metal) / CPU fallback

The trained model is saved as a `.pth` checkpoint and loaded during real-time inference.

---

## ğŸ¥ Real-Time Inference Pipeline

1. Capture frame from webcam (OpenCV)
2. Detect face (MediaPipe)
3. Crop and preprocess face
4. Emotion prediction using trained CNN
5. Temporal smoothing to stabilize predictions
6. Display bounding box + emotion label

---

## ğŸ•’ Temporal Smoothing

To reduce flickering predictions:
- Uses a sliding window majority vote
- Produces smoother and more stable emotion outputs in live video

---

## ğŸ§© Project Structure

emotion-detection-system/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ face/              # Face detection
â”‚   â”œâ”€â”€ models/            # CNN architectures
â”‚   â”œâ”€â”€ preprocessing/     # Dataset & normalization
â”‚   â”œâ”€â”€ training/          # Training pipeline
â”‚   â”œâ”€â”€ realtime/          # Live inference
â”‚
â”œâ”€â”€ notebooks/             # Experiments & analysis
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ config.yaml            # Central configuration
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---

## ğŸ§ª Performance

- **Accuracy:** ~65â€“75% (FER-2013 benchmark)
- **FPS:** ~20â€“30 FPS on MacBook Air M2
- **Latency:** Low (real-time capable)
- **Memory usage:** Optimized for 8 GB RAM

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/IbrahimkhalilullaShaik/emotion-detection-system.git
cd emotion-detection-system

2ï¸âƒ£ Create virtual environment
python -m venv venv
source venv/bin/activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run real-time emotion detection
python -m src.realtime.infer_live

ğŸ“„ License

This project is licensed under the MIT License â€” see the LICENSE file for details.

â¸»

ğŸ‘¤ Author

Ibrahim Khalilullah Shaik
Integrated M.Tech â€“ Computer Science
Interests: Deep Learning, Computer Vision, Quantum Computing
